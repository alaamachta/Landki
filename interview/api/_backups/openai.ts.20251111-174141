import OpenAI from 'openai';
import { logger } from './logger.js';

const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '';
const OPENAI_PROJECT_ID = process.env.OPENAI_PROJECT_ID || '';
const OPENAI_WORKFLOW_ID = process.env.OPENAI_WORKFLOW_ID || '';
const OPENAI_WORKFLOW_VERSION = process.env.OPENAI_WORKFLOW_VERSION || '';
const OPENAI_MODEL = process.env.OPENAI_MODEL || 'gpt-4-turbo-preview';

if (!OPENAI_API_KEY) {
  logger.error('OPENAI_API_KEY is not set');
}

export const openai = new OpenAI({
  apiKey: OPENAI_API_KEY,
  // Removed organization header for project-scoped API key. We'll add explicit OpenAI-Project per request.
});

export interface ChatStreamOptions {
  message: string;
  conversationId?: string;
  locale?: string;
  onToken: (token: string) => void;
  onComplete: (suggestions: string[]) => void;
  onError: (error: Error) => void;
}

export async function streamChatCompletion(options: ChatStreamOptions) {
  const { message, locale = 'de-DE', onToken, onComplete, onError } = options;

  try {
    const systemPrompt = `Du bist ein Interview-Assistent für Alaa und LandKI. 
Du sprichst in der ersten Person ("Ich" = Alaa). 
Standardsprache ist formelles Deutsch (Sie), aber du passt dich der Sprache des Nutzers an.
Sei ehrlich, wenn du dir unsicher bist, und übertreibe nicht.

Wenn du eine Frage nicht beantworten kannst:
1. Sage höflich, dass dir die Information fehlt
2. Biete an, die Frage an Alaa weiterzuleiten
3. Frage nach dem Namen oder ob der Nutzer anonym bleiben möchte
4. Bedanke dich und frage, ob es weitere Fragen gibt

Nach jeder Antwort: Schlage 1-3 sinnvolle Folgefragen vor, basierend auf deinem Wissen und der aktuellen Frage.

Locale: ${locale}`;

    const stream = await openai.chat.completions.create({
      model: OPENAI_MODEL,
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: message }
      ],
      stream: true,
      temperature: 0.7,
      max_tokens: 2000,
    }, {
      headers: OPENAI_PROJECT_ID ? { 'OpenAI-Project': OPENAI_PROJECT_ID } : undefined,
    });

    let fullContent = '';

    for await (const chunk of stream) {
      const content = chunk.choices[0]?.delta?.content || '';
      if (content) {
        fullContent += content;
        onToken(content);
      }
    }

    // Generate follow-up suggestions based on the response
    const suggestions = await generateFollowUpSuggestions(message, fullContent);
    onComplete(suggestions);

  } catch (error) {
    logger.error('OpenAI stream error', error);
    onError(error as Error);
  }
}

async function generateFollowUpSuggestions(userMessage: string, assistantResponse: string): Promise<string[]> {
  try {
    const response = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        {
          role: 'system',
          content: `Du generierst 3 kurze Follow-up-Fragen (je max. 60 Zeichen) basierend auf dem Kontext. 
Antworte nur mit einem JSON-Array von Strings, z.B. ["Frage 1?", "Frage 2?", "Frage 3?"]`
        },
        {
          role: 'user',
          content: `User fragte: "${userMessage}"
Assistant antwortete: "${assistantResponse.slice(0, 500)}"

Generiere 3 Follow-up-Fragen auf Deutsch:`
        }
      ],
      temperature: 0.8,
      max_tokens: 200,
    }, {
      headers: OPENAI_PROJECT_ID ? { 'OpenAI-Project': OPENAI_PROJECT_ID } : undefined,
    });

    const content = response.choices[0]?.message?.content || '[]';
    const suggestions = JSON.parse(content);
    
    if (Array.isArray(suggestions) && suggestions.length > 0) {
      return suggestions.slice(0, 3);
    }
    
    return [];
  } catch (error) {
    logger.warn('Failed to generate suggestions', error);
    return [];
  }
}
